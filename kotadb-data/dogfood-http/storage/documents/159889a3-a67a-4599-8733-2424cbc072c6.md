---
tags:
- file
- kota-db
- ext_rs
---
// BenchmarkService - Unified performance testing and benchmarking functionality
//
// This service extracts benchmarking, stress testing, and performance analysis logic from main.rs
// to provide consistent performance evaluation across all KotaDB interfaces.

use anyhow::Result;
use serde_json::{json, Value};
use std::collections::HashMap;
use std::path::PathBuf;
use std::time::Instant;

use super::DatabaseAccess;
use crate::QueryBuilder;

/// Configuration options for benchmarking operations
#[derive(Debug, Clone)]
pub struct BenchmarkOptions {
    pub operations: usize,
    pub benchmark_type: String,
    pub format: String,
    pub max_search_queries: usize,
    pub quiet: bool,
    pub warm_up_operations: Option<usize>,
    pub concurrent_operations: Option<usize>,
}

impl Default for BenchmarkOptions {
    fn default() -> Self {
        Self {
            operations: 10000,
            benchmark_type: "all".to_string(),
            format: "human".to_string(),
            max_search_queries: 100,
            quiet: false,
            warm_up_operations: Some(100),
            concurrent_operations: Some(1),
        }
    }
}

/// Configuration options for stress testing
#[derive(Debug, Clone)]
pub struct StressTestOptions {
    pub duration_seconds: u64,
    pub concurrent_operations: usize,
    pub operation_mix: OperationMix,
    pub memory_limit_mb: Option<u64>,
    pub target_throughput: Option<u64>,
    pub quiet: bool,
}

impl Default for StressTestOptions {
    fn default() -> Self {
        Self {
            duration_seconds: 60,
            concurrent_operations: 10,
            operation_mix: OperationMix::default(),
            memory_limit_mb: None,
            target_throughput: None,
            quiet: false,
        }
    }
}

/// Configuration for operation mix in stress tests
#[derive(Debug, Clone)]
pub struct OperationMix {
    pub read_percent: u8,
    pub write_percent: u8,
    pub search_percent: u8,
    pub analysis_percent: u8,
}

impl Default for OperationMix {
    fn default() -> Self {
        Self {
            read_percent: 40,
            write_percent: 20,
            search_percent: 30,
            analysis_percent: 10,
        }
    }
}

/// Configuration options for capacity planning
#[derive(Debug, Clone)]
pub struct CapacityPlanningOptions {
    pub current_data_size_mb: u64,
    pub projected_growth_percent: u64,
    pub time_horizon_months: u64,
    pub target_performance_ms: u64,
    pub quiet: bool,
}

impl Default for CapacityPlanningOptions {
    fn default() -> Self {
        Self {
            current_data_size_mb: 1000,
            projected_growth_percent: 100,
            time_horizon_months: 12,
            target_performance_ms: 10,
            quiet: false,
        }
    }
}

/// Benchmark results for a specific operation type
#[derive(Debug, Clone, serde::Serialize)]
pub struct BenchmarkTypeResult {
    pub operations: usize,
    pub total_time_ms: u64,
    pub average_time_ms: f64,
    pub median_time_ms: f64,
    pub p95_time_ms: f64,
    pub p99_time_ms: f64,
    pub operations_per_second: f64,
    pub success_rate: f64,
    pub errors: Vec<String>,
}

/// Overall benchmark results
#[derive(Debug, Clone, serde::Serialize)]
pub struct BenchmarkResult {
    pub operations_completed: usize,
    pub total_time_ms: u64,
    pub operations_per_second: f64,
    pub results_by_type: HashMap<String, BenchmarkTypeResult>,
    pub formatted_output: String,
    pub json_output: Option<Value>,
}

/// Stress test results
#[derive(Debug, Clone, serde::Serialize)]
pub struct StressTestResult {
    pub duration_ms: u64,
    pub total_operations: usize,
    pub operations_per_second: f64,
    pub concurrent_peak: usize,
    pub error_rate: f64,
    pub memory_usage_peak_mb: f64,
    pub latency_percentiles: LatencyPercentiles,
    pub operation_results: HashMap<String, BenchmarkTypeResult>,
    pub stability_score: f64,
    pub bottlenecks_identified: Vec<String>,
}

/// Latency percentile measurements
#[derive(Debug, Clone, serde::Serialize)]
pub struct LatencyPercentiles {
    pub p50_ms: f64,
    pub p90_ms: f64,
    pub p95_ms: f64,
    pub p99_ms: f64,
    pub p999_ms: f64,
}

/// Capacity planning recommendations
#[derive(Debug, Clone, serde::Serialize)]
pub struct CapacityPlanningResult {
    pub current_capacity: CapacityMetrics,
    pub projected_capacity: CapacityMetrics,
    pub recommendations: Vec<CapacityRecommendation>,
    pub resource_requirements: ResourceRequirements,
    pub scaling_thresholds: ScalingThresholds,
}

/// Current or projected capacity metrics
#[derive(Debug, Clone, serde::Serialize)]
pub struct CapacityMetrics {
    pub data_size_mb: u64,
    pub estimated_operations_per_second: u64,
    pub memory_requirement_mb: u64,
    pub storage_requirement_mb: u64,
    pub index_size_mb: u64,
}

/// Capacity planning recommendation
#[derive(Debug, Clone, serde::Serialize)]
pub struct CapacityRecommendation {
    pub category: String,
    pub priority: RecommendationPriority,
    pub description: String,
    pub estimated_impact: String,
    pub implementation_effort: ImplementationEffort,
}

/// Priority levels for recommendations
#[derive(Debug, Clone, serde::Serialize)]
pub enum RecommendationPriority {
    Low,
    Medium,
    High,
    Critical,
}

/// Implementation effort estimates
#[derive(Debug, Clone, serde::Serialize)]
pub enum ImplementationEffort {
    Minimal,
    Low,
    Medium,
    High,
    Extensive,
}

/// Resource requirements projection
#[derive(Debug, Clone, serde::Serialize)]
pub struct ResourceRequirements {
    pub cpu_cores: u32,
    pub memory_gb: u32,
    pub storage_gb: u32,
    pub network_bandwidth_mbps: u32,
    pub estimated_monthly_cost: f64,
}

/// Scaling thresholds and triggers
#[derive(Debug, Clone, serde::Serialize)]
pub struct ScalingThresholds {
    pub cpu_utilization_percent: u8,
    pub memory_utilization_percent: u8,
    pub storage_utilization_percent: u8,
    pub response_time_ms: u64,
    pub throughput_ops_per_second: u64,
}

/// Regression test results comparing against baseline
#[derive(Debug, Clone, serde::Serialize)]
pub struct RegressionTestResult {
    pub overall_regression: bool,
    pub baseline_version: String,
    pub current_version: String,
    pub performance_comparison: PerformanceComparison,
    pub regressions_found: Vec<RegressionIssue>,
    pub improvements_found: Vec<PerformanceImprovement>,
}

/// Performance comparison between versions
#[derive(Debug, Clone, serde::Serialize)]
pub struct PerformanceComparison {
    pub operation_comparisons: HashMap<String, OperationComparison>,
    pub overall_performance_change: f64, // Percentage change
    pub memory_usage_change: f64,
    pub throughput_change: f64,
}

/// Comparison for a specific operation
#[derive(Debug, Clone, serde::Serialize)]
pub struct OperationComparison {
    pub baseline_time_ms: f64,
    pub current_time_ms: f64,
    pub performance_change_percent: f64,
    pub regression_detected: bool,
    pub significance_level: f64,
}

/// Detected regression issue
#[derive(Debug, Clone, serde::Serialize)]
pub struct RegressionIssue {
    pub operation: String,
    pub severity: RegressionSeverity,
    pub performance_impact_percent: f64,
    pub description: String,
    pub suggested_investigation: String,
}

/// Severity levels for regressions
#[derive(Debug, Clone, serde::Serialize)]
pub enum RegressionSeverity {
    Minor,
    Moderate,
    Major,
    Critical,
}

/// Detected performance improvement
#[derive(Debug, Clone, serde::Serialize)]
pub struct PerformanceImprovement {
    pub operation: String,
    pub improvement_percent: f64,
    pub description: String,
}

/// BenchmarkService handles all performance testing, benchmarking, and capacity planning
#[allow(dead_code)]
pub struct BenchmarkService<'a> {
    database: &'a dyn DatabaseAccess,
    db_path: PathBuf,
}

impl<'a> BenchmarkService<'a> {
    /// Create a new BenchmarkService instance
    pub fn new(database: &'a dyn DatabaseAccess, db_path: PathBuf) -> Self {
        Self { database, db_path }
    }

    /// Run comprehensive benchmarks on database operations
    ///
    /// This method extracts the benchmarking logic from main.rs, providing
    /// consistent performance testing across all interfaces.
    pub async fn run_benchmark(&self, options: BenchmarkOptions) -> Result<BenchmarkResult> {
        let start_time = Instant::now();
        let mut results_by_type = HashMap::new();
        let mut formatted_output = String::new();

        if !options.quiet {
            formatted_output.push_str("\n🚀 Running KotaDB Benchmarks\n");
            formatted_output.push_str(&format!("   Operations: {}\n", options.operations));
            formatted_output.push_str(&format!("   Type: {}\n", options.benchmark_type));
            formatted_output.push_str(&format!("   Format: {}\n", options.format));
            formatted_output.push('\n');
        }

        // Warm up if specified
        if let Some(warmup_ops) = options.warm_up_operations {
            if !options.quiet {
                formatted_output.push_str(&format!(
                    "🔥 Warming up with {} operations...\n",
                    warmup_ops
                ));
            }
            self.run_warmup_operations(warmup_ops).await?;
        }

        // Run benchmarks based on type
        match options.benchmark_type.as_str() {
            "storage" => {
                let result = self.benchmark_storage_operations(&options).await?;
                results_by_type.insert("storage".to_string(), result);
            }
            "index" => {
                let result = self.benchmark_index_operations(&options).await?;
                results_by_type.insert("index".to_string(), result);
            }
            "query" => {
                let result = self.benchmark_query_operations(&options).await?;
                results_by_type.insert("query".to_string(), result);
            }
            "search" => {
                let result = self.benchmark_search_operations(&options).await?;
                results_by_type.insert("search".to_string(), result);
            }
            _ => {
                // Run all benchmark types
                let storage_result = self.benchmark_storage_operations(&options).await?;
                results_by_type.insert("storage".to_string(), storage_result);

                let index_result = self.benchmark_index_operations(&options).await?;
                results_by_type.insert("index".to_string(), index_result);

                let query_result = self.benchmark_query_operations(&options).await?;
                results_by_type.insert("query".to_string(), query_result);

                let search_result = self.benchmark_search_operations(&options).await?;
                results_by_type.insert("search".to_string(), search_result);
            }
        }

        // Calculate overall statistics
        let total_operations: usize = results_by_type.values().map(|r| r.operations).sum();
        let total_time_ms = start_time.elapsed().as_millis() as u64;
        let operations_per_second = if total_time_ms > 0 {
            (total_operations as f64 * 1000.0) / total_time_ms as f64
        } else {
            0.0
        };

        // Format output based on requested format
        match options.format.as_str() {
            "json" => {
                let json_output = self.format_benchmark_json(
                    &results_by_type,
                    total_operations,
                    total_time_ms,
                    operations_per_second,
                )?;
                formatted_output.push_str(&serde_json::to_string_pretty(&json_output)?);
            }
            "csv" => {
                formatted_output.push_str(&self.format_benchmark_csv(&results_by_type)?);
            }
            _ => {
                formatted_output.push_str(&self.format_benchmark_human(
                    &results_by_type,
                    total_operations,
                    total_time_ms,
                    operations_per_second,
                )?);
            }
        }

        let json_output = if options.format == "json" {
            Some(self.format_benchmark_json(
                &results_by_type,
                total_operations,
                total_time_ms,
                operations_per_second,
            )?)
        } else {
            None
        };

        Ok(BenchmarkResult {
            operations_completed: total_operations,
            total_time_ms,
            operations_per_second,
            results_by_type,
            formatted_output,
            json_output,
        })
    }

    /// Run stress test with concurrent operations
    pub async fn stress_test(&self, options: StressTestOptions) -> Result<StressTestResult> {
        let mut formatted_output = String::new();

        if !options.quiet {
            formatted_output.push_str(&format!(
                "🧪 Running stress test for {} seconds\n",
                options.duration_seconds
            ));
            formatted_output.push_str(&format!(
                "   Concurrent operations: {}\n",
                options.concurrent_operations
            ));
        }

        // TODO: Implement comprehensive stress testing
        // This would include:
        // - Concurrent operation execution
        // - Memory usage monitoring
        // - Error rate tracking
        // - Latency distribution analysis
        // - Bottleneck identification

        if !options.quiet {
            formatted_output
                .push_str("⚠️  Comprehensive stress testing not yet fully implemented\n");
            formatted_output.push_str("   Use benchmark command for current performance testing\n");
        }

        Ok(StressTestResult {
            duration_ms: options.duration_seconds * 1000,
            total_operations: 0,
            operations_per_second: 0.0,
            concurrent_peak: options.concurrent_operations,
            error_rate: 0.0,
            memory_usage_peak_mb: 0.0,
            latency_percentiles: LatencyPercentiles {
                p50_ms: 0.0,
                p90_ms: 0.0,
                p95_ms: 0.0,
                p99_ms: 0.0,
                p999_ms: 0.0,
            },
            operation_results: HashMap::new(),
            stability_score: 0.0,
            bottlenecks_identified: Vec::new(),
        })
    }

    /// Run performance regression test against baseline
    pub async fn regression_test(
        &self,
        baseline_path: Option<PathBuf>,
    ) -> Result<RegressionTestResult> {
        // TODO: Implement regression testing
        // This would include:
        // - Load baseline performance data
        // - Run current benchmarks
        // - Compare results with statistical significance
        // - Identify regressions and improvements

        Ok(RegressionTestResult {
            overall_regression: false,
            baseline_version: "Not implemented".to_string(),
            current_version: "Not implemented".to_string(),
            performance_comparison: PerformanceComparison {
                operation_comparisons: HashMap::new(),
                overall_performance_change: 0.0,
                memory_usage_change: 0.0,
                throughput_change: 0.0,
            },
            regressions_found: Vec::new(),
            improvements_found: Vec::new(),
        })
    }

    /// Generate capacity planning recommendations
    pub async fn capacity_planning(
        &self,
        options: CapacityPlanningOptions,
    ) -> Result<CapacityPlanningResult> {
        // TODO: Implement capacity planning analysis
        // This would include:
        // - Current capacity assessment
        // - Growth projection modeling
        // - Resource requirement calculation
        // - Scaling threshold recommendations

        Ok(CapacityPlanningResult {
            current_capacity: CapacityMetrics {
                data_size_mb: options.current_data_size_mb,
                estimated_operations_per_second: 1000,
                memory_requirement_mb: 512,
                storage_requirement_mb: options.current_data_size_mb * 2,
                index_size_mb: options.current_data_size_mb / 4,
            },
            projected_capacity: CapacityMetrics {
                data_size_mb: options.current_data_size_mb
                    * (100 + options.projected_growth_percent)
                    / 100,
                estimated_operations_per_second: 2000,
                memory_requirement_mb: 1024,
                storage_requirement_mb: options.current_data_size_mb * 4,
                index_size_mb: options.current_data_size_mb / 2,
            },
            recommendations: Vec::new(),
            resource_requirements: ResourceRequirements {
                cpu_cores: 4,
                memory_gb: 8,
                storage_gb: (options.current_data_size_mb * 4 / 1024) as u32,
                network_bandwidth_mbps: 100,
                estimated_monthly_cost: 150.0,
            },
            scaling_thresholds: ScalingThresholds {
                cpu_utilization_percent: 70,
                memory_utilization_percent: 80,
                storage_utilization_percent: 85,
                response_time_ms: options.target_performance_ms,
                throughput_ops_per_second: 1500,
            },
        })
    }

    // Private implementation methods

    async fn run_warmup_operations(&self, warmup_ops: usize) -> Result<()> {
        // Warm up the database with realistic codebase intelligence operations
        // This ensures consistent performance measurements by stabilizing caches and indices

        let storage = self.database.storage();
        let primary_index = self.database.primary_index();
        let trigram_index = self.database.trigram_index();

        // Warm up with a mix of typical operations
        for i in 0..warmup_ops {
            match i % 3 {
                0 => {
                    // Warm up storage: get some documents via primary index search
                    let index_guard = primary_index.lock().await;
                    let query = QueryBuilder::new().with_limit(3)?.build()?;
                    if let Ok(doc_ids) = index_guard.search(&query).await {
                        if let Some(doc_id) = doc_ids.first() {
                            let storage_guard = storage.lock().await;
                            let _ = storage_guard.get(doc_id).await;
                        }
                    }
                }
                1 => {
                    // Warm up primary index: wildcard search
                    let index_guard = primary_index.lock().await;
                    let query = QueryBuilder::new().with_limit(5)?.build()?;
                    let _ = index_guard.search(&query).await;
                }
                _ => {
                    // Warm up trigram index: common search terms
                    let search_terms = ["async", "struct", "impl", "fn"];
                    let term = &search_terms[i % search_terms.len()];
                    let index_guard = trigram_index.lock().await;
                    let query = QueryBuilder::new().with_text(*term)?.build()?;
                    let _ = index_guard.search(&query).await;
                }
            }
        }

        Ok(())
    }

    async fn benchmark_storage_operations(
        &self,
        options: &BenchmarkOptions,
    ) -> Result<BenchmarkTypeResult> {
        let mut timings = Vec::new();
        let mut errors = Vec::new();
        let start_time = Instant::now();

        // Benchmark actual storage operations: document retrieval and path lookups
        // This tests the real codebase intelligence storage layer performance
        let storage = self.database.storage();
        let primary_index = self.database.primary_index();

        // Get some existing document IDs to benchmark retrieval
        let mut test_doc_ids = Vec::new();
        {
            let index_guard = primary_index.lock().await;
            let query = QueryBuilder::new().with_limit(20)?.build()?;
            if let Ok(doc_ids) = index_guard.search(&query).await {
                test_doc_ids = doc_ids;
            }
        }

        // Benchmark document retrieval operations
        let operations_count = std::cmp::min(options.operations, 1000);
        for i in 0..operations_count {
            let op_start = Instant::now();

            // Benchmark actual document retrieval
            let result = if !test_doc_ids.is_empty() {
                let doc_id = &test_doc_ids[i % test_doc_ids.len()];
                let storage_guard = storage.lock().await;
                storage_guard.get(doc_id).await
            } else {
                // If no documents exist, this is expected - just return None
                Ok(None)
            };

            match result {
                Ok(_) => {
                    timings.push(op_start.elapsed().as_micros() as f64 / 1000.0);
                }
                Err(e) => {
                    errors.push(format!("Storage operation failed: {}", e));
                    // Still record timing for failed operations
                    timings.push(op_start.elapsed().as_micros() as f64 / 1000.0);
                }
            }
        }

        let total_time_ms = start_time.elapsed().as_millis() as u64;
        let operations = timings.len();
        let average_time_ms = if !timings.is_empty() {
            timings.iter().sum::<f64>() / timings.len() as f64
        } else {
            0.0
        };

        timings.sort_by(|a, b| a.partial_cmp(b).unwrap());
        let median_time_ms = if !timings.is_empty() {
            timings[timings.len() / 2]
        } else {
            0.0
        };

        let p95_time_ms = if timings.len() > 20 {
            timings[(timings.len() * 95) / 100]
        } else {
            average_time_ms
        };

        let p99_time_ms = if timings.len() > 100 {
            timings[(timings.len() * 99) / 100]
        } else {
            average_time_ms
        };

        let operations_per_second = if total_time_ms > 0 {
            (operations as f64 * 1000.0) / total_time_ms as f64
        } else {
            0.0
        };

        Ok(BenchmarkTypeResult {
            operations,
            total_time_ms,
            average_time_ms,
            median_time_ms,
            p95_time_ms,
            p99_time_ms,
            operations_per_second,
            success_rate: if operations > 0 {
                1.0 - (errors.len() as f64 / operations as f64)
            } else {
                0.0
            },
            errors,
        })
    }

    async fn benchmark_index_operations(
        &self,
        options: &BenchmarkOptions,
    ) -> Result<BenchmarkTypeResult> {
        let mut timings = Vec::new();
        let mut errors = Vec::new();
        let start_time = Instant::now();

        // Benchmark actual index operations: primary index lookups and trigram search
        // This tests the real codebase intelligence index performance
        let primary_index = self.database.primary_index();
        let trigram_index = self.database.trigram_index();

        // Common search terms to benchmark against indexed content
        let search_terms = vec![
            "async", "struct", "impl", "fn", "use", "pub", "let", "match", "Result", "Error",
            "String", "Vec", "HashMap", "tokio", "serde", "anyhow",
        ];

        let operations_count = std::cmp::min(options.operations, 1000);
        for i in 0..operations_count {
            let op_start = Instant::now();

            // Alternate between primary index searches and trigram searches
            let result = if i % 2 == 0 {
                // Benchmark primary index search operations
                let index_guard = primary_index.lock().await;
                let query = QueryBuilder::new().with_limit(10)?.build()?;
                index_guard.search(&query).await.map(|_| ())
            } else {
                // Benchmark trigram search operations
                let search_term = &search_terms[i % search_terms.len()];
                let index_guard = trigram_index.lock().await;
                let query = QueryBuilder::new().with_text(*search_term)?.build()?;
                index_guard.search(&query).await.map(|_| ())
            };

            match result {
                Ok(_) => {
                    timings.push(op_start.elapsed().as_micros() as f64 / 1000.0);
                }
                Err(e) => {
                    errors.push(format!("Index operation failed: {}", e));
                    // Still record timing for failed operations
                    timings.push(op_start.elapsed().as_micros() as f64 / 1000.0);
                }
            }
        }

        let total_time_ms = start_time.elapsed().as_millis() as u64;
        let operations = timings.len();
        let average_time_ms = if !timings.is_empty() {
            timings.iter().sum::<f64>() / timings.len() as f64
        } else {
            0.0
        };

        timings.sort_by(|a, b| a.partial_cmp(b).unwrap());
        let median_time_ms = if !timings.is_empty() {
            timings[timings.len() / 2]
        } else {
            0.0
        };

        let p95_time_ms = if timings.len() > 20 {
            timings[(timings.len() * 95) / 100]
        } else {
            average_time_ms
        };

        let p99_time_ms = if timings.len() > 100 {
            timings[(timings.len() * 99) / 100]
        } else {
            average_time_ms
        };

        let operations_per_second = if total_time_ms > 0 {
            (operations as f64 * 1000.0) / total_time_ms as f64
        } else {
            0.0
        };

        Ok(BenchmarkTypeResult {
            operations,
            total_time_ms,
            average_time_ms,
            median_time_ms,
            p95_time_ms,
            p99_time_ms,
            operations_per_second,
            success_rate: if operations > 0 {
                1.0 - (errors.len() as f64 / operations as f64)
            } else {
                0.0
            },
            errors,
        })
    }

    async fn benchmark_query_operations(
        &self,
        options: &BenchmarkOptions,
    ) -> Result<BenchmarkTypeResult> {
        let mut timings = Vec::new();
        let mut errors = Vec::new();
        let start_time = Instant::now();

        // Benchmark complex query operations: path-based queries, range scans, pattern matching
        // This tests the real codebase intelligence query engine performance
        let primary_index = self.database.primary_index();
        let trigram_index = self.database.trigram_index();

        // Complex query patterns for codebase intelligence
        let path_patterns = [
            "src/**/*.rs",
            "tests/**/*",
            "*.toml",
            "*.md",
            "*.yml",
            "src/services/*",
            "src/mcp/*",
            "docs/*",
            "benches/*",
        ];

        let complex_queries = [
            "async fn main",
            "impl.*Service",
            "pub struct.*Config",
            "use.*anyhow::Result",
            "#[derive.*Serialize",
            "tokio::.*async",
            "std::collections::HashMap",
            "Result<.*Error>",
        ];

        let operations_count = std::cmp::min(options.operations, 1000);
        for i in 0..operations_count {
            let op_start = Instant::now();

            let result = match i % 3 {
                0 => {
                    // Benchmark wildcard queries
                    let index_guard = primary_index.lock().await;
                    let query = QueryBuilder::new().with_limit(20)?.build()?;
                    index_guard.search(&query).await.map(|_| ())
                }
                1 => {
                    // Benchmark path pattern matching (use path patterns as text)
                    let pattern = &path_patterns[i % path_patterns.len()];
                    let index_guard = primary_index.lock().await;
                    let query = QueryBuilder::new()
                        .with_text(*pattern)?
                        .with_limit(50)?
                        .build()?;
                    index_guard.search(&query).await.map(|_| ())
                }
                _ => {
                    // Benchmark complex trigram queries
                    let complex_query = &complex_queries[i % complex_queries.len()];
                    let index_guard = trigram_index.lock().await;
                    let query = QueryBuilder::new().with_text(*complex_query)?.build()?;
                    index_guard.search(&query).await.map(|_| ())
                }
            };

            match result {
                Ok(_) => {
                    timings.push(op_start.elapsed().as_micros() as f64 / 1000.0);
                }
                Err(e) => {
                    errors.push(format!("Query operation failed: {}", e));
                    // Still record timing for failed operations
                    timings.push(op_start.elapsed().as_micros() as f64 / 1000.0);
                }
            }
        }

        let total_time_ms = start_time.elapsed().as_millis() as u64;
        let operations = timings.len();
        let average_time_ms = if !timings.is_empty() {
            timings.iter().sum::<f64>() / timings.len() as f64
        } else {
            0.0
        };

        timings.sort_by(|a, b| a.partial_cmp(b).unwrap());
        let median_time_ms = if !timings.is_empty() {
            timings[timings.len() / 2]
        } else {
            0.0
        };

        let p95_time_ms = if timings.len() > 20 {
            timings[(timings.len() * 95) / 100]
        } else {
            average_time_ms
        };

        let p99_time_ms = if timings.len() > 100 {
            timings[(timings.len() * 99) / 100]
        } else {
            average_time_ms
        };

        let operations_per_second = if total_time_ms > 0 {
            (operations as f64 * 1000.0) / total_time_ms as f64
        } else {
            0.0
        };

        Ok(BenchmarkTypeResult {
            operations,
            total_time_ms,
            average_time_ms,
            median_time_ms,
            p95_time_ms,
            p99_time_ms,
            operations_per_second,
            success_rate: if operations > 0 {
                1.0 - (errors.len() as f64 / operations as f64)
            } else {
                0.0
            },
            errors,
        })
    }

    async fn benchmark_search_operations(
        &self,
        options: &BenchmarkOptions,
    ) -> Result<BenchmarkTypeResult> {
        let mut timings = Vec::new();
        let mut errors = Vec::new();
        let start_time = Instant::now();

        // Benchmark actual search operations: content search and symbol search
        // This tests the real codebase intelligence SearchService performance
        use super::{SearchOptions, SearchService, SymbolSearchOptions};

        let search_service = SearchService::new(self.database, self.db_path.join("symbols"));

        // Realistic search queries for codebase intelligence
        let content_queries = vec![
            "async fn", "struct", "impl", "Result<", "Error", "Vec<", "HashMap", "tokio",
            "use std", "pub fn", "let mut", "match", "if let", "unwrap", "expect", "clone",
        ];

        let symbol_patterns = [
            "Storage", "Index", "Service", "*Result", "Error*", "Config", "Handler", "Manager",
            "Builder", "Factory", "Trait", "Enum",
        ];

        let operations_count = std::cmp::min(options.operations, options.max_search_queries);
        for i in 0..operations_count {
            let op_start = Instant::now();

            // Alternate between content search and symbol search
            let result = if i % 2 == 0 {
                // Benchmark content search operations
                let query = &content_queries[i % content_queries.len()];
                let search_options = SearchOptions {
                    query: query.to_string(),
                    limit: 10,
                    tags: None,
                    context: "minimal".to_string(), // Use minimal context for performance
                    quiet: true,
                };
                search_service
                    .search_content(search_options)
                    .await
                    .map(|_| ())
            } else {
                // Benchmark symbol search operations
                let pattern = &symbol_patterns[i % symbol_patterns.len()];
                let symbol_options = SymbolSearchOptions {
                    pattern: pattern.to_string(),
                    limit: 10,
                    symbol_type: None,
                    quiet: true,
                };
                search_service
                    .search_symbols(symbol_options)
                    .await
                    .map(|_| ())
            };

            match result {
                Ok(_) => {
                    timings.push(op_start.elapsed().as_micros() as f64 / 1000.0);
                }
                Err(e) => {
                    errors.push(format!("Search operation failed: {}", e));
                    // Still record timing for failed operations
                    timings.push(op_start.elapsed().as_micros() as f64 / 1000.0);
                }
            }
        }

        let total_time_ms = start_time.elapsed().as_millis() as u64;
        let operations = timings.len();
        let average_time_ms = if !timings.is_empty() {
            timings.iter().sum::<f64>() / timings.len() as f64
        } else {
            0.0
        };

        timings.sort_by(|a, b| a.partial_cmp(b).unwrap());
        let median_time_ms = if !timings.is_empty() {
            timings[timings.len() / 2]
        } else {
            0.0
        };

        let p95_time_ms = if timings.len() > 20 {
            timings[(timings.len() * 95) / 100]
        } else {
            average_time_ms
        };

        let p99_time_ms = if timings.len() > 100 {
            timings[(timings.len() * 99) / 100]
        } else {
            average_time_ms
        };

        let operations_per_second = if total_time_ms > 0 {
            (operations as f64 * 1000.0) / total_time_ms as f64
        } else {
            0.0
        };

        Ok(BenchmarkTypeResult {
            operations,
            total_time_ms,
            average_time_ms,
            median_time_ms,
            p95_time_ms,
            p99_time_ms,
            operations_per_second,
            success_rate: if operations > 0 {
                1.0 - (errors.len() as f64 / operations as f64)
            } else {
                0.0
            },
            errors,
        })
    }

    fn format_benchmark_human(
        &self,
        results: &HashMap<String, BenchmarkTypeResult>,
        total_ops: usize,
        total_time_ms: u64,
        ops_per_sec: f64,
    ) -> Result<String> {
        let mut output = String::new();

        output.push_str("📊 Benchmark Results\n");
        output.push_str("===================\n\n");

        output.push_str("Overall Performance:\n");
        output.push_str(&format!("   Total operations: {}\n", total_ops));
        output.push_str(&format!(
            "   Total time: {:.2}s\n",
            total_time_ms as f64 / 1000.0
        ));
        output.push_str(&format!("   Throughput: {:.2} ops/sec\n\n", ops_per_sec));

        for (bench_type, result) in results {
            output.push_str(&format!("{}:\n", bench_type.to_uppercase()));
            output.push_str(&format!("   Operations: {}\n", result.operations));
            output.push_str(&format!(
                "   Average time: {:.2}ms\n",
                result.average_time_ms
            ));
            output.push_str(&format!("   Median time: {:.2}ms\n", result.median_time_ms));
            output.push_str(&format!(
                "   95th percentile: {:.2}ms\n",
                result.p95_time_ms
            ));
            output.push_str(&format!(
                "   99th percentile: {:.2}ms\n",
                result.p99_time_ms
            ));
            output.push_str(&format!(
                "   Throughput: {:.2} ops/sec\n",
                result.operations_per_second
            ));
            output.push_str(&format!(
                "   Success rate: {:.1}%\n",
                result.success_rate * 100.0
            ));
            output.push('\n');
        }

        Ok(output)
    }

    fn format_benchmark_json(
        &self,
        results: &HashMap<String, BenchmarkTypeResult>,
        total_ops: usize,
        total_time_ms: u64,
        ops_per_sec: f64,
    ) -> Result<Value> {
        Ok(json!({
            "overall": {
                "total_operations": total_ops,
                "total_time_ms": total_time_ms,
                "operations_per_second": ops_per_sec,
                "timestamp": chrono::Utc::now().to_rfc3339()
            },
            "results_by_type": results
        }))
    }

    fn format_benchmark_csv(
        &self,
        results: &HashMap<String, BenchmarkTypeResult>,
    ) -> Result<String> {
        let mut output = String::new();

        output.push_str("benchmark_type,operations,total_time_ms,average_time_ms,median_time_ms,p95_time_ms,p99_time_ms,operations_per_second,success_rate\n");

        for (bench_type, result) in results {
            output.push_str(&format!(
                "{},{},{},{:.2},{:.2},{:.2},{:.2},{:.2},{:.3}\n",
                bench_type,
                result.operations,
                result.total_time_ms,
                result.average_time_ms,
                result.median_time_ms,
                result.p95_time_ms,
                result.p99_time_ms,
                result.operations_per_second,
                result.success_rate
            ));
        }

        Ok(output)
    }
}
